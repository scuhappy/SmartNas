import os
import re
import json
import asyncio
import requests
from urllib.parse import quote
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

BASE_URL = "https://javday.app"

async def search_javday(fanhao: str):
    """ä½¿ç”¨ Playwright è®¿é—® javday æœç´¢å¹¶è§£æç»“æœ"""
    url = f"{BASE_URL}/search?wd={quote(fanhao)}"
    results = []

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            extra_http_headers={
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Referer": "https://javday.app/",
                "Connection": "keep-alive",
            },
            ignore_https_errors=True
        )
        page = await context.new_page()

        try:
            print(f"ğŸ” æœç´¢ {fanhao}: {url}")
            await page.goto(url, wait_until="domcontentloaded", timeout=30000)
            await page.wait_for_selector(".videoBox", timeout=15000)
            content = await page.content()

            soup = BeautifulSoup(content, "html.parser")
            for box in soup.select(".videoBox"):
                cover_div = box.select_one(".videoBox-cover")
                cover_url = None
                if cover_div and "style" in cover_div.attrs:
                    m = re.search(r"url\((.*?)\)", cover_div["style"])
                    if m:
                        cover_url = BASE_URL + m.group(1)

                title_span = box.select_one(".videoBox-info .title")
                title = title_span.get_text(strip=True) if title_span else None

                if cover_url and title:
                    results.append({"title": title, "cover": cover_url})

        except Exception as e:
            print(f"âŒ æœç´¢ {fanhao} å¤±è´¥: {e}")
        finally:
            await browser.close()

    return results

async def download_cover(url, fanhao, filename, save_dir="covers", retries=3):
    """ä¸‹è½½å°é¢å¹¶ä»¥è§†é¢‘æ–‡ä»¶åå‘½åï¼Œæ”¯æŒé‡è¯•å’Œå¤‡ç”¨ä¸‹è½½"""
    os.makedirs(save_dir, exist_ok=True)
    save_name = os.path.splitext(filename)[0]
    save_path = os.path.join(save_dir, f"{save_name}.jpg")

    # å°è¯•ä½¿ç”¨ Playwright ä¸‹è½½
    for attempt in range(retries):
        try:
            print(f"ğŸ“¥ å°è¯•ä¸‹è½½ {fanhao} å°é¢ (ç¬¬ {attempt + 1}/{retries}): {url}")
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                context = await browser.new_context(ignore_https_errors=True)
                page = await context.new_page()
                response = await page.goto(url, wait_until="networkidle", timeout=30000)
                if response and response.status == 200:
                    content = await response.body()
                    with open(save_path, "wb") as f:
                        f.write(content)
                    await browser.close()
                    print(f"âœ… {fanhao} å°é¢å·²ä¿å­˜: {save_path}")
                    return save_path
                else:
                    print(f"âš  {fanhao} å°é¢ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status if response else 'æ— å“åº”'}")
                    await browser.close()
        except Exception as e:
            print(f"âŒ {fanhao} å°é¢ä¸‹è½½å¤±è´¥ (ç¬¬ {attempt + 1}/{retries}): {e}")

    # å¤‡ç”¨ä¸‹è½½ï¼šä½¿ç”¨ requests
    print(f"ğŸ”„ å°è¯•ä½¿ç”¨ requests ä¸‹è½½ {fanhao} å°é¢: {url}")
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://javday.app/",
        }
        response = requests.get(url, headers=headers, timeout=15, verify=False)
        response.raise_for_status()
        with open(save_path, "wb") as f:
            f.write(response.content)
        print(f"âœ… {fanhao} å°é¢å·²ä¿å­˜ (requests): {save_path}")
        return save_path
    except Exception as e:
        print(f"âŒ {fanhao} å°é¢ä¸‹è½½å¤±è´¥ (requests): {e}")
        return None

def extract_fanhao(filename):
    """ä»æ–‡ä»¶åä¸­æå–ç•ªå·"""
    match = re.search(r"[A-Z]{2,5}-\d{2,5}", filename, re.I)
    return match.group(0).upper() if match else None

def get_relative_path(path, base_path):
    """è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œå¤„ç†è·¨åˆ†åŒºæƒ…å†µ"""
    try:
        return os.path.relpath(path, base_path).replace(os.sep, '/')
    except ValueError:
        # è·¨åˆ†åŒºæ—¶ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶è§„èŒƒåŒ–
        print(f"âš  è·¨åˆ†åŒºè·¯å¾„: {path} (åŸºäº {base_path})")
        return os.path.abspath(path).replace(os.sep, '/')

async def process_videos(folder_path, json_file="metadata.json"):
    """é€’å½’éå†æ–‡ä»¶å¤¹åŠå…¶å­æ–‡ä»¶å¤¹ï¼Œæå–ç•ªå·ï¼Œä¸‹è½½å°é¢å¹¶ä¿å­˜å…ƒæ•°æ®"""
    video_extensions = ('.mp4', '.mkv', '.avi', '.mov', '.wmv')
    metadata = {}

    # ä½¿ç”¨ folder_path ä½œä¸ºåŸºå‡†è·¯å¾„
    base_path = os.path.abspath(folder_path)

    for root, _, files in os.walk(folder_path):
        for filename in files:
            if filename.lower().endswith(video_extensions):
                fanhao = extract_fanhao(filename)
                if not fanhao:
                    print(f"âš  {filename} æœªæ‰¾åˆ°æœ‰æ•ˆç•ªå·")
                    continue

                print(f"å¤„ç†æ–‡ä»¶: {os.path.join(root, filename)} (ç•ªå·: {fanhao})")
                items = await search_javday(fanhao)

                if not items:
                    print(f"âš  {fanhao} æ²¡æœ‰æ‰¾åˆ°ç»“æœ")
                    continue

                # åªå¤„ç†ç¬¬ä¸€ä¸ªæœç´¢ç»“æœ
                item = items[0]
                cover_path = await download_cover(item["cover"], fanhao, filename)
                if cover_path:
                    # è®¡ç®—ç›¸å¯¹äº folder_path çš„è·¯å¾„
                    relative_cover_path = get_relative_path(cover_path, base_path)
                    relative_video_path = get_relative_path(os.path.join(root, filename), base_path)
                    metadata[fanhao] = {
                        "title": item["title"],
                        "cover_path": relative_cover_path,
                        "video_file": relative_video_path
                    }

    # ä¿å­˜å…ƒæ•°æ®åˆ° JSON æ–‡ä»¶
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=4)
    print(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜è‡³: {json_file}")

async def main():
    # æŒ‡å®šè§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
    folder_path = "G:/Videos"  # è¯·æ›¿æ¢ä¸ºä½ çš„è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
    if not os.path.exists(folder_path):
        print(f"âŒ æ–‡ä»¶å¤¹ {folder_path} ä¸å­˜åœ¨")
        return

    await process_videos(folder_path)

if __name__ == "__main__":
    asyncio.run(main())